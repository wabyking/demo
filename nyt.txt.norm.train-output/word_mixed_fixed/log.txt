Namespace(add_phase_shift=0, batch_size=128, do_eval=0, emb_dimension=50, from_scatch=1, iterations=5, log_step=100, lr=0.0025, min_count=25, output='nyt.txt.norm.train-output', text='nyt.txt.norm.train', time_scale=1, time_type='word_mixed_fixed', use_time=1, verbose=0, weight_decay=1e-11, window_size=5, years=30)
Loss in 0 steps: 1.3862944841384888 0.6931472420692444, 0.6931472420692444
Loss in 100 steps: 1.1619147062301636 0.4946271479129791, 0.6672876477241516
Loss in 200 steps: 1.1007589101791382 0.532236635684967, 0.5685223340988159
Loss in 300 steps: 1.0598547458648682 0.5140071511268616, 0.5458475947380066
Loss in 400 steps: 1.055819034576416 0.5157445073127747, 0.5400745272636414
Loss in 500 steps: 1.033473253250122 0.4999145269393921, 0.5335586667060852
Loss in 600 steps: 1.0345426797866821 0.5065354704856873, 0.5280072093009949
Loss in 700 steps: 1.025754451751709 0.5022782683372498, 0.523476243019104
Loss in 800 steps: 0.9984764456748962 0.47749173641204834, 0.5209847688674927
Loss in 900 steps: 1.0153169631958008 0.4966915547847748, 0.5186253786087036
Loss in 1000 steps: 1.1166085004806519 0.5968294143676758, 0.5197792053222656
Loss in 1100 steps: 0.986203670501709 0.4759608805179596, 0.5102428197860718
Loss in 1200 steps: 0.9978129863739014 0.4857802093029022, 0.5120327472686768
Loss in 1300 steps: 0.9892247319221497 0.4815714955329895, 0.5076532363891602
Loss in 1400 steps: 0.9849771857261658 0.4770975410938263, 0.5078796744346619
Loss in 1500 steps: 0.9884395599365234 0.4839317202568054, 0.504507839679718
Loss in 1600 steps: 0.9701266288757324 0.4681510925292969, 0.5019755363464355
Loss in 1700 steps: 0.9636104106903076 0.4633384644985199, 0.5002720355987549
Loss in 1800 steps: 0.9675992727279663 0.4685295522212982, 0.4990696907043457
Loss in 1900 steps: 0.964390754699707 0.4665599763393402, 0.49783074855804443
Loss in 2000 steps: 0.9900736212730408 0.4878615140914917, 0.5022121667861938
Loss in 2100 steps: 0.9644117951393127 0.4692758321762085, 0.4951358735561371
Loss in 2200 steps: 0.9709685444831848 0.47664424777030945, 0.49432432651519775
Loss in 2300 steps: 0.9639002680778503 0.46922942996025085, 0.49467092752456665
Loss in 2400 steps: 0.9717692732810974 0.47787967324256897, 0.49388962984085083
Loss in 2500 steps: 0.9623472690582275 0.4706048369407654, 0.49174243211746216
Loss in 2600 steps: 0.9466126561164856 0.45576363801956177, 0.49084892868995667
Loss in 2700 steps: 0.9583947658538818 0.4655851721763611, 0.492809534072876
Loss in 2800 steps: 0.9668734669685364 0.4753102660179138, 0.49156320095062256
Loss in 2900 steps: 0.958582878112793 0.468910276889801, 0.4896727204322815
Loss in 3000 steps: 0.9506094455718994 0.4639749526977539, 0.4866345226764679
Loss in 3100 steps: 0.9539312720298767 0.46461591124534607, 0.48931536078453064
Loss in 3200 steps: 0.9460260272026062 0.4583330750465393, 0.4876929521560669
Loss in 3300 steps: 0.9471011161804199 0.4626944065093994, 0.4844067394733429
Loss in 3400 steps: 0.9363794922828674 0.45132240653038025, 0.4850570857524872
Loss in 3500 steps: 0.9474713206291199 0.4598768949508667, 0.4875943660736084
Loss in 3600 steps: 0.9546592235565186 0.4657547175884247, 0.4889044761657715
Loss in 3700 steps: 0.9379956722259521 0.4503900706768036, 0.48760560154914856
Loss in 3800 steps: 0.918834924697876 0.4375401437282562, 0.48129478096961975
Loss in 3900 steps: 0.9634034037590027 0.4784441590309143, 0.4849591553211212
Loss in 4000 steps: 0.935799241065979 0.4528134763240814, 0.4829857647418976
Loss in 4100 steps: 0.9589490294456482 0.4698801338672638, 0.4890688955783844
Loss in 4200 steps: 0.9816248416900635 0.4887727200984955, 0.49285221099853516
Loss in 4300 steps: 0.9025725722312927 0.42486441135406494, 0.47770828008651733
Loss in 4400 steps: 0.9410253763198853 0.4582575559616089, 0.48276782035827637
Loss in 4500 steps: 0.9352461695671082 0.4536212086677551, 0.4816250205039978
Loss in 4600 steps: 0.9301327466964722 0.4480573832988739, 0.4820753335952759
Loss in 4700 steps: 0.9519268870353699 0.4701414704322815, 0.4817854166030884
Loss in 4800 steps: 0.9268409013748169 0.4455198347568512, 0.4813210964202881
Loss in 4900 steps: 0.9147922992706299 0.4386786222457886, 0.4761136770248413
Loss in 5000 steps: 0.923672080039978 0.44380491971969604, 0.47986721992492676
Loss in 5100 steps: 0.9590621590614319 0.4757309556007385, 0.48333120346069336
Loss in 5200 steps: 0.9368456602096558 0.45473188161849976, 0.4821137487888336
Loss in 5300 steps: 0.9357209205627441 0.45410099625587463, 0.48161986470222473
Loss in 5400 steps: 0.9443984031677246 0.4630059003829956, 0.48139259219169617
Loss in 5500 steps: 0.9525819420814514 0.47216740250587463, 0.480414479970932
Loss in 5600 steps: 0.9172075986862183 0.4410362243652344, 0.4761713445186615
Loss in 5700 steps: 0.9374178051948547 0.45718663930892944, 0.4802311360836029
Loss in 5800 steps: 0.9348631501197815 0.45649245381355286, 0.478370726108551
Loss in 5900 steps: 0.9357510805130005 0.4559987485408783, 0.4797523617744446
Loss in 6000 steps: 0.9348667860031128 0.45540449023246765, 0.47946229577064514
Loss in 6100 steps: 0.9248551726341248 0.4486127495765686, 0.47624239325523376
Loss in 6200 steps: 0.8968495726585388 0.42465758323669434, 0.47219187021255493
Loss in 6300 steps: 0.9312853813171387 0.45139312744140625, 0.47989222407341003
Loss in 6400 steps: 0.9173669815063477 0.44149520993232727, 0.4758718013763428
Loss in 6500 steps: 0.933533251285553 0.4524077773094177, 0.48112550377845764
Loss in 6600 steps: 0.9324809908866882 0.4523106813430786, 0.48017022013664246
Loss in 6700 steps: 0.9256449937820435 0.44831982254981995, 0.4773252010345459
Loss in 6800 steps: 0.9326230883598328 0.45639699697494507, 0.4762260615825653
Loss in 6900 steps: 0.9280573129653931 0.4525068700313568, 0.4755503833293915
Loss in 7000 steps: 0.9492701888084412 0.46950992941856384, 0.4797602593898773
Loss in 7100 steps: 0.9349851012229919 0.4583359956741333, 0.47664910554885864
Loss in 7200 steps: 0.9185294508934021 0.443637877702713, 0.4748915731906891
Loss in 7300 steps: 0.9043236374855042 0.43344491720199585, 0.4708787202835083
Loss in 7400 steps: 0.9340643882751465 0.4581463634967804, 0.4759179651737213
Loss in 7500 steps: 0.9174264669418335 0.4415755271911621, 0.4758509397506714
Loss in 7600 steps: 0.918592095375061 0.44267967343330383, 0.47591233253479004
Loss in 7700 steps: 0.9167830944061279 0.44147926568984985, 0.4753037989139557
Loss in 7800 steps: 0.9233435392379761 0.4461391270160675, 0.47720441222190857
Loss in 7900 steps: 0.9234778881072998 0.4447883665561676, 0.4786895215511322
Loss in 8000 steps: 0.9343129992485046 0.45558977127075195, 0.4787231683731079
Loss in 8100 steps: 0.9513712525367737 0.47264376282691956, 0.47872743010520935
Loss in 8200 steps: 0.9224756956100464 0.4418509006500244, 0.4806247651576996
Loss in 8300 steps: 0.9282940626144409 0.4522671401500702, 0.47602689266204834
Loss in 8400 steps: 0.9125785231590271 0.43541836738586426, 0.47716015577316284
Loss in 8500 steps: 0.9391582012176514 0.4618561267852783, 0.47730201482772827
Loss in 8600 steps: 0.9250168800354004 0.4490322768688202, 0.4759845733642578
Loss in 8700 steps: 0.919032633304596 0.4423234760761261, 0.47670912742614746
Loss in 8800 steps: 0.9316286444664001 0.4545181691646576, 0.4771105945110321
Loss in 8900 steps: 0.9255905747413635 0.4505826234817505, 0.47500792145729065
Loss in 9000 steps: 0.9485363960266113 0.4704133868217468, 0.4781229794025421
Loss in 9100 steps: 0.9074319005012512 0.43501102924346924, 0.4724208414554596
Loss in 9200 steps: 0.943166196346283 0.4655892550945282, 0.47757694125175476
Loss in 9300 steps: 0.9295738339424133 0.45223361253738403, 0.4773401618003845
Loss in 9400 steps: 0.9262002110481262 0.45299363136291504, 0.47320660948753357
Loss in 9500 steps: 0.9227114319801331 0.44667211174964905, 0.47603943943977356
Loss in 9600 steps: 0.9481104016304016 0.4740261137485504, 0.4740843176841736
Loss in 9700 steps: 0.9082945585250854 0.43589064478874207, 0.4724039137363434
Loss in 9800 steps: 0.9244709610939026 0.4500633776187897, 0.47440770268440247
Loss in 9900 steps: 0.8998069763183594 0.4284448027610779, 0.4713621735572815
Loss in 10000 steps: 0.9407204985618591 0.4644586741924286, 0.47626176476478577
Loss in 10100 steps: 0.9258723855018616 0.4536079466342926, 0.4722644090652466
Loss in 10200 steps: 0.9222338199615479 0.4470330774784088, 0.4752006530761719
Loss in 10300 steps: 0.9072437286376953 0.43636947870254517, 0.47087427973747253
Loss in 10400 steps: 0.9241666793823242 0.44933968782424927, 0.47482699155807495
Loss in 10500 steps: 0.9352005124092102 0.4588839113712311, 0.4763166010379791
Loss in 10600 steps: 0.9052864909172058 0.4336216151714325, 0.4716648757457733
Loss in 10700 steps: 0.9048551917076111 0.4288387894630432, 0.47601640224456787
Loss in 10800 steps: 0.9274483919143677 0.45244958996772766, 0.47499874234199524
Loss in 10900 steps: 0.9059666395187378 0.4362313151359558, 0.46973535418510437
Loss in 11000 steps: 0.9102070927619934 0.43820661306381226, 0.47200047969818115
Loss in 11100 steps: 0.9019535183906555 0.4295133650302887, 0.4724401533603668
Loss in 11200 steps: 0.9474740624427795 0.47205713391304016, 0.47541695833206177
Loss in 11300 steps: 0.9012195467948914 0.4307383596897125, 0.4704812467098236
Loss in 11400 steps: 0.9116538166999817 0.4392554759979248, 0.4723983407020569
Loss in 11500 steps: 0.9048065543174744 0.43559038639068604, 0.46921616792678833
Loss in 11600 steps: 0.9004406929016113 0.4347977340221405, 0.4656429886817932
Loss in 11700 steps: 0.9321745038032532 0.4565906822681427, 0.4755837619304657
Loss in 11800 steps: 0.9238014221191406 0.4494897723197937, 0.4743116796016693
Loss in 11900 steps: 0.8958814144134521 0.42547082901000977, 0.4704105854034424
Loss in 12000 steps: 0.8972431421279907 0.42504674196243286, 0.47219642996788025
Loss in 12100 steps: 0.8933437466621399 0.42769721150398254, 0.4656464755535126
Loss in 12200 steps: 0.9016876816749573 0.43091538548469543, 0.47077232599258423
Loss in 12300 steps: 0.9221284985542297 0.4483291804790497, 0.47379934787750244
Loss in 12400 steps: 0.9200299382209778 0.443903386592865, 0.4761265218257904
Loss in 12500 steps: 0.9259844422340393 0.4528176486492157, 0.4731667935848236
Loss in 12600 steps: 0.9021481871604919 0.43210527300834656, 0.4700429439544678
Loss in 12700 steps: 0.920792818069458 0.4459654986858368, 0.47482728958129883
Loss in 12800 steps: 0.92141193151474 0.4484631419181824, 0.47294872999191284
Loss in  test0: 0.9145443427628472 
Loss in  test1: 0.913983786803527 
Namespace(add_phase_shift=0, batch_size=128, do_eval=0, emb_dimension=50, from_scatch=1, iterations=5, log_step=100, lr=0.0025, min_count=25, output='nyt.txt.norm.train-output', text='nyt.txt.norm.train', time_scale=1, time_type='word_mixed_fixed', use_time=1, verbose=0, weight_decay=1e-11, window_size=5, years=30)
Loss in 0 steps: 0.91939377784729 0.44884687662124634, 0.4705469012260437
Loss in 100 steps: 0.9263767004013062 0.44918978214263916, 0.47718682885169983
Loss in 200 steps: 0.9058528542518616 0.4329166114330292, 0.4729362726211548
Loss in 300 steps: 0.9157090783119202 0.4397425949573517, 0.47596654295921326
Loss in 400 steps: 0.9005911350250244 0.4335039556026459, 0.46708714962005615
Loss in 500 steps: 0.9110438823699951 0.43710076808929443, 0.4739430844783783
Loss in 600 steps: 0.9392373561859131 0.4649554193019867, 0.4742818772792816
Loss in 700 steps: 0.9173001646995544 0.4471260607242584, 0.470174103975296
Loss in 800 steps: 0.9186615943908691 0.44742777943611145, 0.4712337553501129
Loss in 900 steps: 0.862875759601593 0.40384936332702637, 0.45902642607688904
Loss in 1000 steps: 0.9039512276649475 0.4349559247493744, 0.4689953327178955
Loss in 1100 steps: 0.9231919050216675 0.4491771161556244, 0.47401487827301025
Loss in 1200 steps: 0.9251651167869568 0.4521719217300415, 0.47299325466156006
Loss in 1300 steps: 0.9159644246101379 0.44177407026290894, 0.4741903245449066
Loss in 1400 steps: 0.9245545864105225 0.45313289761543274, 0.4714217483997345
Loss in 1500 steps: 0.9335113763809204 0.4609367847442627, 0.4725746512413025
Loss in 1600 steps: 0.9001786112785339 0.43244054913520813, 0.4677380919456482
Loss in 1700 steps: 0.9339165687561035 0.4629436433315277, 0.47097286581993103
Loss in 1800 steps: 0.9372792840003967 0.46193814277648926, 0.47534114122390747
Loss in 1900 steps: 0.9259812235832214 0.45592671632766724, 0.47005459666252136
Loss in 2000 steps: 0.907589852809906 0.4386816620826721, 0.46890825033187866
Loss in 2100 steps: 0.8993252515792847 0.42925482988357544, 0.47007042169570923
Loss in 2200 steps: 0.9237266182899475 0.45061764121055603, 0.47310906648635864
Loss in 2300 steps: 0.8947113156318665 0.42992642521858215, 0.4647848606109619
Loss in 2400 steps: 0.9303346276283264 0.455992192029953, 0.4743425250053406
Loss in 2500 steps: 0.9188097715377808 0.447151780128479, 0.47165805101394653
Loss in 2600 steps: 0.8982357382774353 0.42761000990867615, 0.47062578797340393
Loss in 2700 steps: 0.9071037173271179 0.43968498706817627, 0.46741873025894165
Loss in 2800 steps: 0.9305450320243835 0.4590573310852051, 0.47148770093917847
Loss in 2900 steps: 0.9176992177963257 0.443390816450119, 0.47430843114852905
Loss in 3000 steps: 0.9152824282646179 0.4439878463745117, 0.471294641494751
Loss in 3100 steps: 0.9189184904098511 0.4458162784576416, 0.47310224175453186
Loss in 3200 steps: 0.9102538824081421 0.44479331374168396, 0.46546056866645813
Loss in 3300 steps: 0.9097940921783447 0.4395095407962799, 0.4702845811843872
Loss in 3400 steps: 0.9225509166717529 0.4517427384853363, 0.47080811858177185
Loss in 3500 steps: 0.9008743166923523 0.4312260150909424, 0.4696483016014099
Loss in 3600 steps: 0.8994301557540894 0.43052685260772705, 0.46890321373939514
Loss in 3700 steps: 0.9102388024330139 0.4430757462978363, 0.4671630263328552
Loss in 3800 steps: 0.8634788393974304 0.4056297838687897, 0.45784908533096313
Loss in 3900 steps: 0.9304443597793579 0.45642468333244324, 0.4740195870399475
Loss in 4000 steps: 0.9288693070411682 0.4547189176082611, 0.4741503894329071
Loss in 4100 steps: 0.9298604130744934 0.4566945433616638, 0.4731658697128296
Loss in 4200 steps: 0.9270383715629578 0.4526060223579407, 0.4744323492050171
Loss in 4300 steps: 0.9059730768203735 0.43437665700912476, 0.47159650921821594
Loss in 4400 steps: 0.9140645861625671 0.44417497515678406, 0.4698896110057831
Loss in 4500 steps: 0.9035104513168335 0.43171432614326477, 0.4717962145805359
Loss in 4600 steps: 0.9035797119140625 0.4309057593345642, 0.4726739823818207
Loss in 4700 steps: 0.8856989741325378 0.4177403748035431, 0.46795862913131714
Loss in 4800 steps: 0.8913701772689819 0.4308251142501831, 0.4605450928211212
Loss in 4900 steps: 0.9054549932479858 0.43322208523750305, 0.47223278880119324
Loss in 5000 steps: 0.8936442732810974 0.4240269362926483, 0.4696173369884491
Loss in 5100 steps: 0.9288536906242371 0.45347413420677185, 0.4753795266151428
Loss in 5200 steps: 0.8997089266777039 0.42864343523979187, 0.4710655212402344
Loss in 5300 steps: 0.901623547077179 0.4303396940231323, 0.47128385305404663
Loss in 5400 steps: 0.9130696058273315 0.4462219476699829, 0.466847687959671
Loss in 5500 steps: 0.9203583598136902 0.44825509190559387, 0.4721032977104187
Loss in 5600 steps: 0.9162132143974304 0.44600871205329895, 0.47020456194877625
Loss in 5700 steps: 0.9346588850021362 0.4626755118370056, 0.471983402967453
Loss in 5800 steps: 0.9181517958641052 0.4501764476299286, 0.467975378036499
Loss in 5900 steps: 0.925369381904602 0.45273691415786743, 0.4726324677467346
Loss in 6000 steps: 0.9181672930717468 0.4455922544002533, 0.47257503867149353
Loss in 6100 steps: 0.9201765060424805 0.44794395565986633, 0.47223255038261414
Loss in 6200 steps: 0.8905538320541382 0.4262373447418213, 0.4643164277076721
Loss in 6300 steps: 0.9059321880340576 0.4389030933380127, 0.4670291244983673
Loss in 6400 steps: 0.907769501209259 0.43941253423690796, 0.4683569669723511
Loss in 6500 steps: 0.9009336829185486 0.433017373085022, 0.4679163098335266
Loss in 6600 steps: 0.897780179977417 0.4311198890209198, 0.4666603207588196
Loss in 6700 steps: 0.9167898297309875 0.44560909271240234, 0.4711807370185852
Loss in 6800 steps: 0.9084205627441406 0.43987470865249634, 0.4685457944869995
Loss in 6900 steps: 0.9137089848518372 0.44244682788848877, 0.471262127161026
Loss in 7000 steps: 0.9151157140731812 0.4456569254398346, 0.46945881843566895
Loss in 7100 steps: 0.9012624025344849 0.43491142988204956, 0.4663509428501129
Loss in 7200 steps: 0.9165913462638855 0.44612863659858704, 0.47046270966529846
Loss in 7300 steps: 0.9052767753601074 0.4369644522666931, 0.4683122932910919
Loss in 7400 steps: 0.9120093584060669 0.4425196051597595, 0.46948978304862976
Loss in 7500 steps: 0.9019503593444824 0.43765199184417725, 0.4642983675003052
Loss in 7600 steps: 0.922919511795044 0.45328107476234436, 0.4696384072303772
Loss in 7700 steps: 0.922986626625061 0.4534285366535187, 0.46955806016921997
Loss in 7800 steps: 0.9192385077476501 0.45018401741981506, 0.46905452013015747
Loss in 7900 steps: 0.9121774435043335 0.4414827823638916, 0.4706946313381195
Loss in 8000 steps: 0.903083324432373 0.4338040053844452, 0.46927934885025024
Loss in 8100 steps: 0.9156482815742493 0.44326603412628174, 0.47238215804100037
Loss in 8200 steps: 0.8882453441619873 0.421076238155365, 0.4671691060066223
Loss in 8300 steps: 0.9011917114257812 0.4334019720554352, 0.46778973937034607
Loss in 8400 steps: 0.90655517578125 0.4363694489002228, 0.47018569707870483
Loss in 8500 steps: 0.9347647428512573 0.4625864326953888, 0.4721783399581909
Loss in 8600 steps: 0.9088846445083618 0.44142401218414307, 0.46746066212654114
Loss in 8700 steps: 0.9149709939956665 0.45073744654655457, 0.46423354744911194
Loss in 8800 steps: 0.9051879644393921 0.43556642532348633, 0.46962159872055054
Loss in 8900 steps: 0.8951325416564941 0.4287952780723572, 0.4663372039794922
Loss in 9000 steps: 0.9166454076766968 0.4470697045326233, 0.4695757031440735
Loss in 9100 steps: 0.9149342775344849 0.44728267192840576, 0.4676515758037567
Loss in 9200 steps: 0.9270582795143127 0.4538576900959015, 0.47320064902305603
Loss in 9300 steps: 0.9345728754997253 0.463977575302124, 0.47059524059295654
Loss in 9400 steps: 0.9143749475479126 0.4440695643424988, 0.47030532360076904
Loss in 9500 steps: 0.9193192720413208 0.4496517479419708, 0.46966752409935
Loss in 9600 steps: 0.9102577567100525 0.44310373067855835, 0.46715396642684937
Loss in 9700 steps: 0.8854679465293884 0.42051658034324646, 0.4649513065814972
Loss in 9800 steps: 0.9350786805152893 0.4641348421573639, 0.4709439277648926
Loss in 9900 steps: 0.8973303437232971 0.4280570447444916, 0.46927332878112793
Loss in 10000 steps: 0.9011861681938171 0.43065759539604187, 0.47052857279777527
Loss in 10100 steps: 0.9121914505958557 0.4417542815208435, 0.4704371690750122
Loss in 10200 steps: 0.9176268577575684 0.4495163559913635, 0.4681105613708496
Loss in 10300 steps: 0.9193639159202576 0.449741005897522, 0.469622939825058
Loss in 10400 steps: 0.9036968946456909 0.4360017478466034, 0.46769511699676514
Loss in 10500 steps: 0.9151666164398193 0.44152629375457764, 0.4736402928829193
Loss in 10600 steps: 0.9093837141990662 0.43953216075897217, 0.469851553440094
Loss in 10700 steps: 0.89706951379776 0.4337601959705353, 0.46330928802490234
Loss in 10800 steps: 0.9017432332038879 0.43604573607444763, 0.4656975567340851
Loss in 10900 steps: 0.9104369282722473 0.43826109170913696, 0.47217580676078796
Loss in 11000 steps: 0.8936068415641785 0.4283123314380646, 0.4652945399284363
Loss in 11100 steps: 0.9041834473609924 0.4363318681716919, 0.46785154938697815
Loss in 11200 steps: 0.8985297083854675 0.4298137128353119, 0.4687160551548004
Loss in 11300 steps: 0.9089818000793457 0.4407719075679779, 0.4682099223136902
Loss in 11400 steps: 0.8869105577468872 0.4202651083469391, 0.46664541959762573
Loss in 11500 steps: 0.9139626026153564 0.4441317319869995, 0.46983084082603455
Loss in 11600 steps: 0.8966169357299805 0.4331180155277252, 0.46349892020225525
Loss in 11700 steps: 0.9111292362213135 0.44106656312942505, 0.47006261348724365
Loss in 11800 steps: 0.9163735508918762 0.44566982984542847, 0.4707036316394806
Loss in 11900 steps: 0.9097355008125305 0.44089579582214355, 0.4688396453857422
Loss in 12000 steps: 0.902521550655365 0.4333060681819916, 0.4692154824733734
Loss in 12100 steps: 0.9347875714302063 0.4608014225959778, 0.47398608922958374
Loss in 12200 steps: 0.9310296177864075 0.46346762776374817, 0.4675620198249817
Loss in 12300 steps: 0.8937883377075195 0.42612186074256897, 0.4676664173603058
Loss in 12400 steps: 0.9302520155906677 0.4579985737800598, 0.47225338220596313
Loss in 12500 steps: 0.902377188205719 0.433342307806015, 0.46903494000434875
Loss in 12600 steps: 0.9180311560630798 0.44656428694725037, 0.47146695852279663
Loss in 12700 steps: 0.9055740237236023 0.43569502234458923, 0.46987906098365784
Loss in 12800 steps: 0.9059318900108337 0.43727102875709534, 0.468660831451416
Loss in  test0: 0.9076791358442353 
Loss in  test1: 0.9069168627627958 
Namespace(add_phase_shift=0, batch_size=128, do_eval=0, emb_dimension=50, from_scatch=1, iterations=5, log_step=100, lr=0.0025, min_count=25, output='nyt.txt.norm.train-output', text='nyt.txt.norm.train', time_scale=1, time_type='word_mixed_fixed', use_time=1, verbose=0, weight_decay=1e-11, window_size=5, years=30)
Loss in 0 steps: 0.9246060252189636 0.45415592193603516, 0.4704500734806061
Loss in 100 steps: 0.8954225182533264 0.42952629923820496, 0.4658961594104767
Loss in 200 steps: 0.9231593608856201 0.45314913988113403, 0.4700102210044861
Loss in 300 steps: 0.8868425488471985 0.4201393127441406, 0.4667032063007355
Loss in 400 steps: 0.8904447555541992 0.42359763383865356, 0.4668470621109009
Loss in 500 steps: 0.9048967361450195 0.4368455111980438, 0.46805116534233093
Loss in 600 steps: 0.891901433467865 0.4250822961330414, 0.4668191969394684
Loss in 700 steps: 0.9137201905250549 0.4473438262939453, 0.4663764536380768
Loss in 800 steps: 0.9120469689369202 0.4454801678657532, 0.4665667712688446
Loss in 900 steps: 0.9076442718505859 0.43768057227134705, 0.4699636697769165
Loss in 1000 steps: 0.8799964785575867 0.4210113286972046, 0.45898517966270447
Loss in 1100 steps: 0.9025865197181702 0.4381161332130432, 0.46447041630744934
Loss in 1200 steps: 0.9085626006126404 0.44163796305656433, 0.4669245779514313
Loss in 1300 steps: 0.9213753938674927 0.45006468892097473, 0.47131070494651794
Loss in 1400 steps: 0.8982470035552979 0.4294512867927551, 0.4687957167625427
Loss in 1500 steps: 0.9187439680099487 0.44617119431495667, 0.4725726842880249
Loss in 1600 steps: 0.9007431268692017 0.4343929588794708, 0.46635010838508606
Loss in 1700 steps: 0.8936407566070557 0.425019770860672, 0.4686209559440613
Loss in 1800 steps: 0.8835683465003967 0.4228196442127228, 0.46074873208999634
Loss in 1900 steps: 0.8863139152526855 0.42182186245918274, 0.4644920229911804
Loss in 2000 steps: 0.8987926840782166 0.4320061504840851, 0.46678659319877625
Loss in 2100 steps: 0.9040485620498657 0.4359310567378998, 0.46811753511428833
Loss in 2200 steps: 0.923534631729126 0.45444589853286743, 0.4690887928009033
Loss in 2300 steps: 0.8908981680870056 0.42430245876312256, 0.46659573912620544
Loss in 2400 steps: 0.9347701668739319 0.4633236229419708, 0.4714464843273163
Loss in 2500 steps: 0.8845750689506531 0.42063432931900024, 0.46394070982933044
Loss in 2600 steps: 0.8967334628105164 0.4286435842514038, 0.46808987855911255
Loss in 2700 steps: 0.8946052193641663 0.4300978481769562, 0.4645073115825653
Loss in 2800 steps: 0.9229718446731567 0.449903279542923, 0.47306859493255615
Loss in 2900 steps: 0.8997591733932495 0.4333275258541107, 0.4664316475391388
Loss in 3000 steps: 0.9258396029472351 0.4564075171947479, 0.4694320857524872
Loss in 3100 steps: 0.8930363059043884 0.4275711178779602, 0.4654651880264282
Loss in 3200 steps: 0.8882653117179871 0.4241443872451782, 0.46412089467048645
Loss in 3300 steps: 0.9124916195869446 0.4427735209465027, 0.46971800923347473
Loss in 3400 steps: 0.9225544333457947 0.4504193067550659, 0.47213512659072876
Loss in 3500 steps: 0.9085445404052734 0.4396583139896393, 0.46888625621795654
Loss in 3600 steps: 0.906324565410614 0.4406978487968445, 0.4656267464160919
Loss in 3700 steps: 0.9296494126319885 0.45646238327026367, 0.47318702936172485
Loss in 3800 steps: 0.8874919414520264 0.42229872941970825, 0.46519312262535095
Loss in 3900 steps: 0.9177189469337463 0.4450436234474182, 0.47267529368400574
Loss in 4000 steps: 0.8887078762054443 0.42347264289855957, 0.46523526310920715
Loss in 4100 steps: 0.9276682138442993 0.4587189257144928, 0.46894922852516174
Loss in 4200 steps: 0.9024916887283325 0.4336235523223877, 0.4688682556152344
Loss in 4300 steps: 0.9039378762245178 0.4364430904388428, 0.4674948453903198
Loss in 4400 steps: 0.9006894826889038 0.4380234479904175, 0.46266597509384155
Loss in 4500 steps: 0.9058319926261902 0.43892157077789307, 0.46691039204597473
Loss in 4600 steps: 0.8879804015159607 0.4238438904285431, 0.4641365110874176
Loss in 4700 steps: 0.8915352821350098 0.42407023906707764, 0.46746498346328735
Loss in 4800 steps: 0.8897929787635803 0.4256804883480072, 0.46411243081092834
Loss in 4900 steps: 0.9115787744522095 0.4444951117038727, 0.4670836627483368
Loss in 5000 steps: 0.9035048484802246 0.43653789162635803, 0.46696701645851135
Loss in 5100 steps: 0.919199526309967 0.4477352499961853, 0.47146424651145935
Loss in 5200 steps: 0.8857784271240234 0.42237892746925354, 0.4633994698524475
Loss in 5300 steps: 0.9195818305015564 0.4479105770587921, 0.47167131304740906
Loss in 5400 steps: 0.874809741973877 0.4149138927459717, 0.4598958492279053
Loss in 5500 steps: 0.9133261442184448 0.4461238980293274, 0.4672023057937622
Loss in 5600 steps: 0.887370765209198 0.4205871522426605, 0.4667835533618927
Loss in 5700 steps: 0.8867818713188171 0.42234960198402405, 0.4644322693347931
Loss in 5800 steps: 0.9303359389305115 0.4601001441478729, 0.4702357351779938
Loss in 5900 steps: 0.8918153643608093 0.42625486850738525, 0.46556052565574646
Loss in 6000 steps: 0.9290165901184082 0.45864444971084595, 0.47037217020988464
Loss in 6100 steps: 0.9215124845504761 0.4514789879322052, 0.4700334668159485
Loss in 6200 steps: 0.9061582088470459 0.43559083342552185, 0.47056734561920166
Loss in 6300 steps: 0.9080601334571838 0.43940863013267517, 0.4686514735221863
Loss in 6400 steps: 0.9170517921447754 0.446561723947525, 0.47049009799957275
Loss in 6500 steps: 0.9011909365653992 0.43226903676986694, 0.4689219892024994
Loss in 6600 steps: 0.9067448973655701 0.439618855714798, 0.4671260416507721
Loss in 6700 steps: 0.9030613899230957 0.43405425548553467, 0.46900713443756104
Loss in 6800 steps: 0.9264914393424988 0.45650047063827515, 0.46999090909957886
Loss in 6900 steps: 0.892096757888794 0.4283362329006195, 0.46376049518585205
Loss in 7000 steps: 0.9098266959190369 0.4441273510456085, 0.46569931507110596
Loss in 7100 steps: 0.9136770367622375 0.44665101170539856, 0.46702608466148376
Loss in 7200 steps: 0.9253652691841125 0.4538949429988861, 0.47147029638290405
Loss in 7300 steps: 0.9040340185165405 0.4384658634662628, 0.4655682146549225
Loss in 7400 steps: 0.9212442636489868 0.45115604996681213, 0.4700881838798523
Loss in 7500 steps: 0.9062471389770508 0.4417109787464142, 0.4645361602306366
Loss in 7600 steps: 0.9102911949157715 0.44519367814064026, 0.46509742736816406
Loss in 7700 steps: 0.909388542175293 0.4416390657424927, 0.4677494466304779
Loss in 7800 steps: 0.9194385409355164 0.4489096403121948, 0.4705290198326111
Loss in 7900 steps: 0.9064775109291077 0.4384390711784363, 0.4680384397506714
Loss in 8000 steps: 0.916498601436615 0.44803619384765625, 0.46846234798431396
Loss in 8100 steps: 0.9038985967636108 0.4337967038154602, 0.47010189294815063
Loss in 8200 steps: 0.9199625253677368 0.4506434202194214, 0.4693191349506378
Loss in 8300 steps: 0.8956771492958069 0.42946264147758484, 0.46621453762054443
Loss in 8400 steps: 0.8912374973297119 0.4265040457248688, 0.4647334814071655
Loss in 8500 steps: 0.9038749933242798 0.43822041153907776, 0.46565452218055725
Loss in 8600 steps: 0.8998432755470276 0.4323800802230835, 0.46746325492858887
Loss in 8700 steps: 0.9069344997406006 0.43972107768058777, 0.4672134220600128
Loss in 8800 steps: 0.9305734038352966 0.4617752134799957, 0.4687982201576233
Loss in 8900 steps: 0.8871808052062988 0.4203501343727112, 0.4668307304382324
Loss in 9000 steps: 0.8928490281105042 0.4273310899734497, 0.46551796793937683
Loss in 9100 steps: 0.9052392244338989 0.43828099966049194, 0.4669581949710846
Loss in 9200 steps: 0.9003418684005737 0.4316883087158203, 0.46865352988243103
Loss in 9300 steps: 0.9141765832901001 0.444879949092865, 0.4692966341972351
Loss in 9400 steps: 0.8819856643676758 0.4163115322589874, 0.46567416191101074
Loss in 9500 steps: 0.9305983781814575 0.46069470047950745, 0.46990370750427246
Loss in 9600 steps: 0.8882516622543335 0.4311714172363281, 0.4570801556110382
Loss in 9700 steps: 0.9092670679092407 0.442416250705719, 0.46685081720352173
Loss in 9800 steps: 0.9249550700187683 0.45573657751083374, 0.4692184627056122
Loss in 9900 steps: 0.9045978784561157 0.43482503294944763, 0.4697727859020233
Loss in 10000 steps: 0.894662618637085 0.42695608735084534, 0.4677065312862396
Loss in 10100 steps: 0.8990730047225952 0.4314766526222229, 0.4675963222980499
Loss in 10200 steps: 0.9177849888801575 0.4509415328502655, 0.46684345602989197
Loss in 10300 steps: 0.918277382850647 0.44803810119628906, 0.47023922204971313
Loss in 10400 steps: 0.8997171521186829 0.4293537437915802, 0.4703633785247803
Loss in 10500 steps: 0.8877221345901489 0.42245379090309143, 0.4652682840824127
Loss in 10600 steps: 0.9116939306259155 0.4446154832839966, 0.46707838773727417
Loss in 10700 steps: 0.9236051440238953 0.4544539451599121, 0.4691512882709503
Loss in 10800 steps: 0.8965298533439636 0.43090569972991943, 0.465624064207077
Loss in 10900 steps: 0.9143351316452026 0.44648948311805725, 0.4678455889225006
Loss in 11000 steps: 0.9189378619194031 0.4491972029209137, 0.4697406589984894
Loss in 11100 steps: 0.9183563590049744 0.44984397292137146, 0.4685123860836029
Loss in 11200 steps: 0.9121378660202026 0.4423139989376068, 0.46982383728027344
Loss in 11300 steps: 0.9097990393638611 0.4412406384944916, 0.4685583710670471
Loss in 11400 steps: 0.8974273204803467 0.4282659590244293, 0.46916133165359497
Loss in 11500 steps: 0.9025846123695374 0.43652281165122986, 0.46606186032295227
Loss in 11600 steps: 0.9241494536399841 0.4562418460845947, 0.467907577753067
Loss in 11700 steps: 0.8988429307937622 0.43191245198249817, 0.46693047881126404
Loss in 11800 steps: 0.8914068341255188 0.42746883630752563, 0.4639379382133484
Loss in 11900 steps: 0.9271009564399719 0.45833444595336914, 0.46876657009124756
Loss in 12000 steps: 0.902610719203949 0.43482309579849243, 0.4677876830101013
Loss in 12100 steps: 0.8947765827178955 0.4282853305339813, 0.46649131178855896
Loss in 12200 steps: 0.8952164053916931 0.4263595640659332, 0.4688567519187927
Loss in 12300 steps: 0.9277881979942322 0.4594561457633972, 0.46833205223083496
Loss in 12400 steps: 0.9047539830207825 0.4337475597858429, 0.4710063934326172
Loss in 12500 steps: 0.9036346077919006 0.435796856880188, 0.46783772110939026
Loss in 12600 steps: 0.9069719314575195 0.4387458860874176, 0.4682261049747467
Loss in 12700 steps: 0.8994879126548767 0.43341150879859924, 0.46607646346092224
Loss in 12800 steps: 0.8905878663063049 0.42701950669288635, 0.46356841921806335
Loss in  test0: 0.9039403051357893 
Loss in  test1: 0.9033580639128751 
Namespace(add_phase_shift=0, batch_size=128, do_eval=0, emb_dimension=50, from_scatch=1, iterations=5, log_step=100, lr=0.0025, min_count=25, output='nyt.txt.norm.train-output', text='nyt.txt.norm.train', time_scale=1, time_type='word_mixed_fixed', use_time=1, verbose=0, weight_decay=1e-11, window_size=5, years=30)
Loss in 0 steps: 0.8887701630592346 0.42422565817832947, 0.46454450488090515
Loss in 100 steps: 0.884860634803772 0.41922256350517273, 0.46563801169395447
Loss in 200 steps: 0.9256829023361206 0.45658692717552185, 0.46909597516059875
Loss in 300 steps: 0.8832969069480896 0.4234044551849365, 0.45989251136779785
Loss in 400 steps: 0.8847314715385437 0.4193107783794403, 0.465420663356781
Loss in 500 steps: 0.9103390574455261 0.4426553249359131, 0.46768373250961304
Loss in 600 steps: 0.9192072749137878 0.4488242268562317, 0.47038301825523376
Loss in 700 steps: 0.9098891615867615 0.44464927911758423, 0.46523982286453247
Loss in 800 steps: 0.9004881381988525 0.4337655305862427, 0.46672266721725464
Loss in 900 steps: 0.8804835677146912 0.4190159738063812, 0.4614676535129547
Loss in 1000 steps: 0.8974477052688599 0.4325747787952423, 0.46487292647361755
Loss in 1100 steps: 0.8963406682014465 0.43001481890678406, 0.4663257896900177
Loss in 1200 steps: 0.916594922542572 0.45274555683135986, 0.46384939551353455
Loss in 1300 steps: 0.8885647654533386 0.4237605333328247, 0.4648042917251587
Loss in 1400 steps: 0.8949795961380005 0.4303511381149292, 0.4646284282207489
Loss in 1500 steps: 0.9098414182662964 0.43962544202804565, 0.4702160358428955
Loss in 1600 steps: 0.8991877436637878 0.4349892735481262, 0.46419861912727356
Loss in 1700 steps: 0.9073641300201416 0.44054606556892395, 0.46681803464889526
Loss in 1800 steps: 0.8935526013374329 0.4260618984699249, 0.46749070286750793
Loss in 1900 steps: 0.9127848148345947 0.4449075758457184, 0.46787717938423157
Loss in 2000 steps: 0.8992785811424255 0.4334123134613037, 0.46586623787879944
Loss in 2100 steps: 0.8933662176132202 0.4266716241836548, 0.46669450402259827
Loss in 2200 steps: 0.8986872434616089 0.432354599237442, 0.46633264422416687
Loss in 2300 steps: 0.8857121467590332 0.4218069612979889, 0.4639052152633667
Loss in 2400 steps: 0.9072707891464233 0.440219908952713, 0.4670507609844208
Loss in 2500 steps: 0.8993139266967773 0.4339737594127655, 0.46534013748168945
Loss in 2600 steps: 0.9022059440612793 0.437222421169281, 0.46498361229896545
Loss in 2700 steps: 0.8941056728363037 0.4284447729587555, 0.465660959482193
Loss in 2800 steps: 0.9048441648483276 0.43905794620513916, 0.4657862186431885
Loss in 2900 steps: 0.899908721446991 0.4325154721736908, 0.4673932194709778
Loss in 3000 steps: 0.9010421633720398 0.43833035230636597, 0.4627118706703186
Loss in 3100 steps: 0.9089474678039551 0.4409008324146271, 0.4680466651916504
Loss in 3200 steps: 0.9293289184570312 0.4585666060447693, 0.47076231241226196
Loss in 3300 steps: 0.9151087403297424 0.4496210515499115, 0.46548768877983093
Loss in 3400 steps: 0.8799393177032471 0.41909340023994446, 0.460845947265625
Loss in 3500 steps: 0.9156392812728882 0.4489383399486542, 0.4667009115219116
Loss in 3600 steps: 0.9062542915344238 0.43773677945137024, 0.4685175120830536
Loss in 3700 steps: 0.8961101174354553 0.4319700300693512, 0.4641400873661041
Loss in 3800 steps: 0.8925527930259705 0.42424654960632324, 0.46830621361732483
Loss in 3900 steps: 0.8929340243339539 0.4299941062927246, 0.46293994784355164
Loss in 4000 steps: 0.8965463638305664 0.4305826425552368, 0.46596381068229675
Loss in 4100 steps: 0.9060021042823792 0.4439028799533844, 0.4620992839336395
Loss in 4200 steps: 0.9282254576683044 0.45799532532691956, 0.4702301025390625
Loss in 4300 steps: 0.8871243596076965 0.4356010854244232, 0.4515232443809509
Loss in 4400 steps: 0.9167333245277405 0.4478784501552582, 0.46885478496551514
Loss in 4500 steps: 0.8996936678886414 0.43212297558784485, 0.4675706923007965
Loss in 4600 steps: 0.901311457157135 0.4356091618537903, 0.46570223569869995
Loss in 4700 steps: 0.9009804725646973 0.4322279095649719, 0.4687526226043701
Loss in 4800 steps: 0.9132064580917358 0.4482687711715698, 0.4649377465248108
Loss in 4900 steps: 0.8975228667259216 0.4319668412208557, 0.4655560255050659
Loss in 5000 steps: 0.90043044090271 0.4341609477996826, 0.46626952290534973
Loss in 5100 steps: 0.893812894821167 0.4288255274295807, 0.46498730778694153
Loss in 5200 steps: 0.8945075869560242 0.42790845036506653, 0.46659910678863525
Loss in 5300 steps: 0.9063239097595215 0.4432579278945923, 0.4630659520626068
Loss in 5400 steps: 0.9253048896789551 0.45764559507369995, 0.46765923500061035
Loss in 5500 steps: 0.9134565591812134 0.44814929366111755, 0.4653072953224182
Loss in 5600 steps: 0.9237169623374939 0.45622724294662476, 0.4674898386001587
Loss in 5700 steps: 0.9050083756446838 0.4375993311405182, 0.46740901470184326
Loss in 5800 steps: 0.9058749079704285 0.4388299882411957, 0.4670448899269104
Loss in 5900 steps: 0.8871084451675415 0.4253658056259155, 0.4617425799369812
Loss in 6000 steps: 0.8861470222473145 0.424717515707016, 0.46142956614494324
Loss in 6100 steps: 0.8959177136421204 0.43080538511276245, 0.4651123583316803
Loss in 6200 steps: 0.9200258255004883 0.4514315724372864, 0.4685942530632019
Loss in 6300 steps: 0.9277170896530151 0.4583583176136017, 0.46935874223709106
Loss in 6400 steps: 0.9103014469146729 0.44219112396240234, 0.4681103825569153
Loss in 6500 steps: 0.9006476998329163 0.437492698431015, 0.4631550908088684
Loss in 6600 steps: 0.9009059071540833 0.43274757266044617, 0.4681582450866699
Loss in 6700 steps: 0.8968949317932129 0.4281735420227051, 0.4687214195728302
Loss in 6800 steps: 0.9179304242134094 0.4507349133491516, 0.4671954810619354
Loss in 6900 steps: 0.9130602478981018 0.44280171394348145, 0.470258504152298
Loss in 7000 steps: 0.91191166639328 0.4445539712905884, 0.4673577547073364
Loss in 7100 steps: 0.9109479188919067 0.4411830008029938, 0.46976491808891296
Loss in 7200 steps: 0.884976327419281 0.418639600276947, 0.46633678674697876
Loss in 7300 steps: 0.9075852036476135 0.44036179780960083, 0.4672233760356903
Loss in 7400 steps: 0.9047423005104065 0.43948209285736084, 0.46526020765304565
Loss in 7500 steps: 0.8801923394203186 0.4170571267604828, 0.463135302066803
Loss in 7600 steps: 0.9071666598320007 0.43926966190338135, 0.4678970277309418
Loss in 7700 steps: 0.9227032661437988 0.4525209069252014, 0.4701824188232422
Loss in 7800 steps: 0.9136701822280884 0.443962961435318, 0.46970728039741516
Loss in 7900 steps: 0.9044474959373474 0.43788835406303406, 0.46655920147895813
Loss in 8000 steps: 0.9137355089187622 0.44364267587661743, 0.4700928330421448
Loss in 8100 steps: 0.8889581561088562 0.4284914433956146, 0.4604666829109192
Loss in 8200 steps: 0.882655680179596 0.4226209819316864, 0.46003466844558716
Loss in 8300 steps: 0.892787754535675 0.422927588224411, 0.4698602259159088
Loss in 8400 steps: 0.8854041695594788 0.42229992151260376, 0.46310415863990784
Loss in 8500 steps: 0.8941025733947754 0.429311066865921, 0.464791476726532
Loss in 8600 steps: 0.8891773223876953 0.42719921469688416, 0.46197810769081116
Loss in 8700 steps: 0.9136657118797302 0.44974586367607117, 0.46391984820365906
Loss in 8800 steps: 0.9065538644790649 0.44486695528030396, 0.461686909198761
Loss in 8900 steps: 0.894489586353302 0.42892715334892273, 0.4655624330043793
Loss in 9000 steps: 0.8742165565490723 0.4163306653499603, 0.45788589119911194
Loss in 9100 steps: 0.9166884422302246 0.44783666729927063, 0.46885186433792114
Loss in 9200 steps: 0.897487461566925 0.43047258257865906, 0.4670148491859436
Loss in 9300 steps: 0.9209730625152588 0.4507785439491272, 0.470194548368454
Loss in 9400 steps: 0.9003206491470337 0.4340198040008545, 0.4663008451461792
Loss in 9500 steps: 0.8982563018798828 0.4338667690753937, 0.464389443397522
Loss in 9600 steps: 0.887701690196991 0.4228518307209015, 0.4648497700691223
Loss in 9700 steps: 0.9012865424156189 0.43461355566978455, 0.46667301654815674
Loss in 9800 steps: 0.8793624639511108 0.41826099157333374, 0.4611014723777771
Loss in 9900 steps: 0.9264752864837646 0.45786669850349426, 0.4686085879802704
Loss in 10000 steps: 0.9096018671989441 0.4455721080303192, 0.4640297591686249
Loss in 10100 steps: 0.8905693888664246 0.4291773736476898, 0.46139201521873474
Loss in 10200 steps: 0.9088163375854492 0.44278016686439514, 0.4660361707210541
Loss in 10300 steps: 0.9166339635848999 0.44902944564819336, 0.46760454773902893
Loss in 10400 steps: 0.8946412205696106 0.4294525682926178, 0.4651886522769928
Loss in 10500 steps: 0.8904911875724792 0.42617252469062805, 0.46431872248649597
Loss in 10600 steps: 0.8862003087997437 0.4238678216934204, 0.46233251690864563
Loss in 10700 steps: 0.9070430397987366 0.4417615234851837, 0.46528151631355286
Loss in 10800 steps: 0.9309672117233276 0.463338702917099, 0.46762847900390625
Loss in 10900 steps: 0.911758303642273 0.44308939576148987, 0.46866893768310547
Loss in 11000 steps: 0.9060529470443726 0.4383811056613922, 0.46767187118530273
Loss in 11100 steps: 0.8965980410575867 0.4292425513267517, 0.46735551953315735
Loss in 11200 steps: 0.8534265160560608 0.40031126141548157, 0.45311522483825684
Loss in 11300 steps: 0.9122661352157593 0.4450072646141052, 0.4672588109970093
Loss in 11400 steps: 0.8984649777412415 0.4313361942768097, 0.4671287536621094
Loss in 11500 steps: 0.9142000675201416 0.44892826676368713, 0.46527180075645447
Loss in 11600 steps: 0.9071256518363953 0.44054853916168213, 0.4665771424770355
Loss in 11700 steps: 0.8946965932846069 0.4299735426902771, 0.46472305059432983
Loss in 11800 steps: 0.8603065609931946 0.40498530864715576, 0.45532116293907166
Loss in 11900 steps: 0.9007863998413086 0.4360358417034149, 0.4647504687309265
Loss in 12000 steps: 0.9069775342941284 0.4446640610694885, 0.4623134434223175
Loss in 12100 steps: 0.907130777835846 0.44178393483161926, 0.4653467833995819
Loss in 12200 steps: 0.894361138343811 0.4259045422077179, 0.46845659613609314
Loss in 12300 steps: 0.9185190796852112 0.4502421021461487, 0.4682769179344177
Loss in 12400 steps: 0.8993914127349854 0.43446677923202515, 0.4649246633052826
Loss in 12500 steps: 0.911201000213623 0.44270873069763184, 0.4684922695159912
Loss in 12600 steps: 0.9039192795753479 0.43848752975463867, 0.4654317796230316
Loss in 12700 steps: 0.9136280417442322 0.44715049862861633, 0.46647754311561584
Loss in 12800 steps: 0.8946490287780762 0.4320929944515228, 0.46255603432655334
Loss in  test0: 0.901764406824286 
Loss in  test1: 0.9011721131397974 
Namespace(add_phase_shift=0, batch_size=128, do_eval=0, emb_dimension=50, from_scatch=1, iterations=5, log_step=100, lr=0.0025, min_count=25, output='nyt.txt.norm.train-output', text='nyt.txt.norm.train', time_scale=1, time_type='word_mixed_fixed', use_time=1, verbose=0, weight_decay=1e-11, window_size=5, years=30)
Loss in 0 steps: 0.9070963859558105 0.43883565068244934, 0.4682607054710388
Loss in 100 steps: 0.9001066088676453 0.43418654799461365, 0.465920090675354
Loss in 200 steps: 0.9083797335624695 0.438821017742157, 0.46955880522727966
Loss in 300 steps: 0.9053511619567871 0.4371436834335327, 0.46820753812789917
Loss in 400 steps: 0.889824628829956 0.42841973900794983, 0.46140486001968384
Loss in 500 steps: 0.906801164150238 0.44497519731521606, 0.46182605624198914
Loss in 600 steps: 0.8902004957199097 0.42675530910491943, 0.46344512701034546
Loss in 700 steps: 0.9160106778144836 0.44695836305618286, 0.4690522849559784
Loss in 800 steps: 0.9028730392456055 0.43901264667510986, 0.4638604521751404
Loss in 900 steps: 0.8902037143707275 0.42645350098609924, 0.4637502431869507
Loss in 1000 steps: 0.8841447830200195 0.4237569570541382, 0.46038779616355896
Loss in 1100 steps: 0.9076857566833496 0.44102731347084045, 0.46665841341018677
Loss in 1200 steps: 0.9009339809417725 0.4361729621887207, 0.4647609293460846
Loss in 1300 steps: 0.8995471596717834 0.433649480342865, 0.46589773893356323
Loss in 1400 steps: 0.9151557683944702 0.4461561143398285, 0.4689997136592865
Loss in 1500 steps: 0.9160452485084534 0.44778361916542053, 0.46826156973838806
Loss in 1600 steps: 0.8924097418785095 0.42551904916763306, 0.46689075231552124
Loss in 1700 steps: 0.9201134443283081 0.45278623700141907, 0.46732714772224426
Loss in 1800 steps: 0.8932267427444458 0.42732611298561096, 0.46590059995651245
Loss in 1900 steps: 0.9068224430084229 0.4373805820941925, 0.46944189071655273
Loss in 2000 steps: 0.902180552482605 0.4376923739910126, 0.4644881784915924
Loss in 2100 steps: 0.9070131182670593 0.43717339634895325, 0.4698397219181061
Loss in 2200 steps: 0.9174789190292358 0.4507500231266022, 0.4667288661003113
Loss in 2300 steps: 0.8818100690841675 0.41817766427993774, 0.4636323153972626
Loss in 2400 steps: 0.9030830264091492 0.440044105052948, 0.4630388915538788
Loss in 2500 steps: 0.885418176651001 0.4249234199523926, 0.4604948163032532
Loss in 2600 steps: 0.8899293541908264 0.4255615472793579, 0.4643678069114685
Loss in 2700 steps: 0.9129211902618408 0.44406843185424805, 0.4688527286052704
Loss in 2800 steps: 0.8913002610206604 0.4273405373096466, 0.4639597237110138
Loss in 2900 steps: 0.8745775818824768 0.41249150037765503, 0.462086021900177
Loss in 3000 steps: 0.9002132415771484 0.4354172945022583, 0.4647960066795349
Loss in 3100 steps: 0.8895559310913086 0.4251037836074829, 0.4644520580768585
Loss in 3200 steps: 0.8788902759552002 0.41738322377204895, 0.46150702238082886
Loss in 3300 steps: 0.9003919363021851 0.4336135983467102, 0.46677833795547485
Loss in 3400 steps: 0.9083288311958313 0.44143515825271606, 0.46689367294311523
Loss in 3500 steps: 0.8953643441200256 0.4320511519908905, 0.4633132219314575
Loss in 3600 steps: 0.9061877131462097 0.4402863681316376, 0.46590131521224976
Loss in 3700 steps: 0.9028679728507996 0.43733951449394226, 0.4655284881591797
Loss in 3800 steps: 0.8964626789093018 0.4313639998435974, 0.4650985896587372
Loss in 3900 steps: 0.9017969965934753 0.43816235661506653, 0.4636346995830536
Loss in 4000 steps: 0.8907421827316284 0.42605745792388916, 0.46468472480773926
Loss in 4100 steps: 0.9070488810539246 0.4416150152683258, 0.4654339551925659
Loss in 4200 steps: 0.8950377702713013 0.42966246604919434, 0.46537530422210693
Loss in 4300 steps: 0.905196487903595 0.44054532051086426, 0.4646511971950531
Loss in 4400 steps: 0.9019675254821777 0.43658849596977234, 0.4653790295124054
Loss in 4500 steps: 0.8918547630310059 0.4259645640850067, 0.46589022874832153
Loss in 4600 steps: 0.8913249969482422 0.42749109864234924, 0.4638339579105377
Loss in 4700 steps: 0.8954090476036072 0.4316592514514923, 0.46374979615211487
Loss in 4800 steps: 0.8981946706771851 0.43432286381721497, 0.46387186646461487
Loss in 4900 steps: 0.8953777551651001 0.43124744296073914, 0.46413034200668335
Loss in 5000 steps: 0.8954889178276062 0.4286421239376068, 0.46684688329696655
Loss in 5100 steps: 0.9124067425727844 0.44904935359954834, 0.4633573889732361
Loss in 5200 steps: 0.8847081065177917 0.429431676864624, 0.4552764594554901
Loss in 5300 steps: 0.9114758968353271 0.44604355096817017, 0.4654322862625122
Loss in 5400 steps: 0.904339075088501 0.4372379779815674, 0.467101126909256
Loss in 5500 steps: 0.8883810639381409 0.42273449897766113, 0.4656466543674469
Loss in 5600 steps: 0.8826062679290771 0.41915804147720337, 0.463448166847229
Loss in 5700 steps: 0.919795572757721 0.45042869448661804, 0.4693669080734253
Loss in 5800 steps: 0.8930867910385132 0.43028441071510315, 0.46280238032341003
Loss in 5900 steps: 0.8922314047813416 0.42526885867118835, 0.46696242690086365
Loss in 6000 steps: 0.9004956483840942 0.4349431097507477, 0.46555259823799133
Loss in 6100 steps: 0.8963025808334351 0.4320014715194702, 0.46430104970932007
Loss in 6200 steps: 0.8863762021064758 0.42329028248786926, 0.4630858600139618
Loss in 6300 steps: 0.9123204946517944 0.4446386396884918, 0.467681884765625
Loss in 6400 steps: 0.8746886849403381 0.414245069026947, 0.4604437053203583
Loss in 6500 steps: 0.8988855481147766 0.43343836069107056, 0.46544718742370605
Loss in 6600 steps: 0.9007783532142639 0.4345591366291046, 0.46621930599212646
Loss in 6700 steps: 0.8805078864097595 0.41959133744239807, 0.46091657876968384
Loss in 6800 steps: 0.9107875823974609 0.44752100110054016, 0.46326664090156555
Loss in 6900 steps: 0.8857326507568359 0.42242446541786194, 0.463308185338974
Loss in 7000 steps: 0.9097538590431213 0.4473518133163452, 0.4624021053314209
Loss in 7100 steps: 0.8979231715202332 0.4346413016319275, 0.46328192949295044
Loss in 7200 steps: 0.9113093018531799 0.4468174874782562, 0.46449190378189087
Loss in 7300 steps: 0.8851584196090698 0.41988229751586914, 0.46527597308158875
Loss in 7400 steps: 0.9225802421569824 0.4581579267978668, 0.4644223153591156
Loss in 7500 steps: 0.8917210102081299 0.42751210927963257, 0.46420881152153015
Loss in 7600 steps: 0.9073469042778015 0.4429440200328827, 0.4644029140472412
Loss in 7700 steps: 0.897638738155365 0.431555837392807, 0.466082900762558
Loss in 7800 steps: 0.8861886858940125 0.4262581467628479, 0.45993050932884216
Loss in 7900 steps: 0.9077688455581665 0.4423094391822815, 0.4654594659805298
Loss in 8000 steps: 0.9133680462837219 0.44603949785232544, 0.46732857823371887
Loss in 8100 steps: 0.9099132418632507 0.44191640615463257, 0.46799689531326294
Loss in 8200 steps: 0.9160428047180176 0.44853055477142334, 0.46751224994659424
Loss in 8300 steps: 0.8877800703048706 0.42545652389526367, 0.4623235762119293
Loss in 8400 steps: 0.9139507412910461 0.44944676756858826, 0.4645039141178131
Loss in 8500 steps: 0.8793129920959473 0.4152733385562897, 0.4640396535396576
Loss in 8600 steps: 0.8925560116767883 0.43065500259399414, 0.4619010090827942
Loss in 8700 steps: 0.9027462601661682 0.43721267580986023, 0.46553361415863037
Loss in 8800 steps: 0.9176084995269775 0.45046117901802063, 0.4671473503112793
Loss in 8900 steps: 0.9130379557609558 0.445258766412735, 0.4677792489528656
Loss in 9000 steps: 0.9095964431762695 0.44251948595046997, 0.46707701683044434
Loss in 9100 steps: 0.8904493451118469 0.42534008622169495, 0.46510928869247437
Loss in 9200 steps: 0.8945090770721436 0.42803284525871277, 0.4664762318134308
Loss in 9300 steps: 0.8849655389785767 0.4232019782066345, 0.4617636203765869
Loss in 9400 steps: 0.9085720777511597 0.4416758716106415, 0.4668962061405182
Loss in 9500 steps: 0.9063751101493835 0.4433809816837311, 0.46299421787261963
Loss in 9600 steps: 0.8942844271659851 0.43347010016441345, 0.46081432700157166
Loss in 9700 steps: 0.8939699530601501 0.43129459023475647, 0.4626753330230713
Loss in 9800 steps: 0.8939440250396729 0.42825064063072205, 0.4656934142112732
Loss in 9900 steps: 0.8994424343109131 0.43489712476730347, 0.4645453095436096
Loss in 10000 steps: 0.9024736881256104 0.4372558891773224, 0.4652177691459656
Loss in 10100 steps: 0.898585319519043 0.4344126880168915, 0.4641726016998291
Loss in 10200 steps: 0.8951180577278137 0.4301193058490753, 0.4649987816810608
Loss in 10300 steps: 0.9174213409423828 0.4508925974369049, 0.4665287733078003
Loss in 10400 steps: 0.885445773601532 0.42474138736724854, 0.46070432662963867
Loss in 10500 steps: 0.9166194796562195 0.45001381635665894, 0.4666057229042053
Loss in 10600 steps: 0.9098103642463684 0.4438799023628235, 0.46593043208122253
Loss in 10700 steps: 0.8884432315826416 0.4283364713191986, 0.4601067006587982
Loss in 10800 steps: 0.8947283029556274 0.42969006299972534, 0.4650382101535797
Loss in 10900 steps: 0.8989951014518738 0.43783581256866455, 0.461159348487854
Loss in 11000 steps: 0.8875557780265808 0.4248771369457245, 0.46267861127853394
Loss in 11100 steps: 0.8988494277000427 0.4338851273059845, 0.4649643301963806
Loss in 11200 steps: 0.916857898235321 0.45111119747161865, 0.46574676036834717
Loss in 11300 steps: 0.8998007774353027 0.4350064992904663, 0.46479424834251404
Loss in 11400 steps: 0.8888856172561646 0.4251266121864319, 0.4637589752674103
Loss in 11500 steps: 0.9056628346443176 0.4373379945755005, 0.4683249592781067
Loss in 11600 steps: 0.8860271573066711 0.4310895502567291, 0.4549376964569092
Loss in 11700 steps: 0.8865712881088257 0.42393621802330017, 0.4626350402832031
Loss in 11800 steps: 0.8887664079666138 0.427663117647171, 0.46110329031944275
Loss in 11900 steps: 0.8891830444335938 0.4258519113063812, 0.4633311927318573
Loss in 12000 steps: 0.9062600135803223 0.440616637468338, 0.4656432867050171
Loss in 12100 steps: 0.8977681398391724 0.43296292424201965, 0.4648052155971527
Loss in 12200 steps: 0.8817846179008484 0.4187338948249817, 0.4630507230758667
Loss in 12300 steps: 0.9033146500587463 0.43788695335388184, 0.46542760729789734
Loss in 12400 steps: 0.8953683972358704 0.4296952784061432, 0.4656730592250824
Loss in 12500 steps: 0.9127263426780701 0.4447689354419708, 0.46795740723609924
Loss in 12600 steps: 0.8892737627029419 0.4259868860244751, 0.4632868468761444
Loss in 12700 steps: 0.9076303243637085 0.4380871653556824, 0.4695431888103485
Loss in 12800 steps: 0.9042379856109619 0.43927502632141113, 0.4649629294872284
Loss in  test0: 0.9012312924572012 
Loss in  test1: 0.900663706484064 
